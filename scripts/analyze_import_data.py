#!/usr/bin/env python
"""
Script to analyze biodiversity, neighborhoods, and localities data for the Urban Tree Observatory project.

This script:
1. Loads and validates CSV and JSON files
2. Identifies any missing neighborhood IDs referenced in biodiversity records
3. Checks the hierarchical relationships between neighborhoods and localities
4. Provides a summary of data integrity issues

Usage:
    python analyze_import_data.py
    python analyze_import_data.py > output.txt

Requirements:
    - pandas
    - json

Note. This script and the hardcoded conclusions were generated by Claude Code,
as part of the analysis of the data import process. It has been committed to the
repository for future reference.
"""

import json
import pandas as pd
from pathlib import Path

# Define file paths
biodiversity_path = '../backend/data/csv/biodiversity.csv'
hoods_path = '../backend/data/json/hoods.json'
localities_path = '../backend/data/json/localities.json'

def load_data():
    """Load data from CSV and JSON files."""
    print("Loading data...")
    
    # Load biodiversity data
    bio_df = pd.read_csv(biodiversity_path)
    print(f"Loaded {len(bio_df)} biodiversity records")
    
    # Load neighborhoods data
    with open(hoods_path, 'r') as f:
        hoods_data = json.load(f)
    hoods = hoods_data['hoods']
    print(f"Loaded {len(hoods)} neighborhoods")
    
    # Load localities data
    with open(localities_path, 'r') as f:
        localities_data = json.load(f)
    localities = localities_data['localities']
    print(f"Loaded {len(localities)} localities")
    
    return bio_df, hoods, localities

def analyze_hoods_ids(bio_df, hoods):
    """Analyze neighborhood IDs in biodiversity data."""
    print("\n===== NEIGHBORHOOD ID ANALYSIS =====")
    
    # Get all unique hood_ids from biodiversity records
    bio_hood_ids = set(bio_df['hood_id'].unique())
    
    # Get all hood ids from hoods.json
    hood_ids = {hood['id'] for hood in hoods}
    
    # Find missing hood ids
    missing_hood_ids = bio_hood_ids - hood_ids
    
    if missing_hood_ids:
        print(f"WARNING: Found {len(missing_hood_ids)} neighborhood IDs in biodiversity records that don't exist in hoods.json")
        print(f"Missing IDs: {sorted(missing_hood_ids)}")
        
        # Analyze records with missing hood_ids
        for missing_id in sorted(missing_hood_ids):
            missing_records = bio_df[bio_df['hood_id'] == missing_id]
            print(f"\nRecords with missing hood_id {missing_id}:")
            print(f"  Count: {len(missing_records)}")
            print(f"  Common names: {missing_records['common_name'].unique()}")
            print(f"  Site IDs: {missing_records['site_id'].unique()}")
    else:
        print("All neighborhood IDs in biodiversity records exist in hoods.json")
    
    # Report highest hood_id
    highest_hood_id = max(hood_ids)
    print(f"Highest hood_id in hoods.json: {highest_hood_id}")

def check_hierarchical_relationships(hoods, localities):
    """Check the hierarchical relationships between neighborhoods and localities."""
    print("\n===== HIERARCHICAL RELATIONSHIP ANALYSIS =====")
    
    # Get all locality IDs from localities.json
    locality_ids = {locality['id'] for locality in localities}
    
    # Find hood locality_ids that don't exist in localities
    invalid_locality_refs = set()
    for hood in hoods:
        if hood['locality_id'] not in locality_ids:
            invalid_locality_refs.add(hood['locality_id'])
    
    if invalid_locality_refs:
        print(f"WARNING: Found {len(invalid_locality_refs)} locality IDs referenced by neighborhoods that don't exist")
        print(f"Invalid locality IDs: {sorted(invalid_locality_refs)}")
    else:
        print("All locality IDs referenced by neighborhoods exist in localities.json")
    
    # Check if unknown locality (ID 14) exists
    if 14 in locality_ids:
        print("Locality ID 14 (unknown/Desconocida) exists in localities.json")
    else:
        print("WARNING: Locality ID 14 (unknown/Desconocida) does not exist in localities.json")

def analyze_site_localities(bio_df, hoods):
    """Analyze site and locality relationships in biodiversity records."""
    print("\n===== SITE AND LOCALITY ANALYSIS =====")
    
    # Create a mapping of hood_id to locality_id
    hood_to_locality = {hood['id']: hood['locality_id'] for hood in hoods}
    
    # Create a subset of biodiversity data with site_id and hood_id
    bio_subset = bio_df[['code_record', 'site_id', 'hood_id']].copy()
    
    # Add locality_id based on hood_id
    bio_subset['hood_locality_id'] = bio_subset['hood_id'].map(hood_to_locality)
    
    # Count records with missing hood_locality_id (due to missing hood_id)
    missing_locality = bio_subset['hood_locality_id'].isna().sum()
    if missing_locality > 0:
        print(f"WARNING: {missing_locality} records have hood_ids that don't map to a locality")
        
    # Group by site_id and count unique localities
    site_locality_counts = bio_subset.groupby('site_id')['hood_locality_id'].nunique()
    
    # Find sites with multiple localities
    multi_locality_sites = site_locality_counts[site_locality_counts > 1]
    if not multi_locality_sites.empty:
        print(f"WARNING: Found {len(multi_locality_sites)} sites with records from multiple localities")
        print(multi_locality_sites)
    else:
        print("Each site has records from only one locality (good consistency)")

def analyze_sites_data(bio_df):
    """Analyze site relationships in biodiversity records."""
    print("\n===== SITE ANALYSIS =====")
    
    # Get all unique site_ids from biodiversity records
    bio_site_ids = bio_df['site_id'].unique()
    print(f"Found {len(bio_site_ids)} unique site IDs in biodiversity records")
    
    # Count records per site
    site_counts = bio_df['site_id'].value_counts()
    
    # Show top 5 sites by record count
    print("\nTop 5 sites by number of biodiversity records:")
    for site_id, count in site_counts.head(5).items():
        print(f"  Site ID {site_id}: {count} records")
    
    # Find if site_id 495 is particularly relevant (appeared in sample data)
    if 495 in site_counts:
        print(f"\nSite ID 495 has {site_counts[495]} records")
        
        # Get unique neighborhoods for site 495
        site_495_hoods = bio_df[bio_df['site_id'] == 495]['hood_id'].unique()
        print(f"  Site 495 is associated with {len(site_495_hoods)} unique neighborhoods")
        print(f"  Neighborhood IDs: {sorted(site_495_hoods)}")

def generate_summary_report(bio_df, hoods, localities):
    """Generate a summary report of the data."""
    print("\n===== DATA SUMMARY REPORT =====")
    
    # Biodiversity records summary
    print(f"Total biodiversity records: {len(bio_df)}")
    print(f"Unique species IDs: {bio_df['species_id'].nunique()}")
    print(f"Unique site IDs: {bio_df['site_id'].nunique()}")
    print(f"Unique neighborhood IDs: {bio_df['hood_id'].nunique()}")
    
    # Neighborhoods summary
    print(f"\nTotal neighborhoods: {len(hoods)}")
    locality_counts = {}
    for hood in hoods:
        locality_id = hood['locality_id']
        locality_counts[locality_id] = locality_counts.get(locality_id, 0) + 1
    
    print(f"Neighborhoods per locality:")
    for locality_id, count in sorted(locality_counts.items()):
        locality_name = next((loc['name'] for loc in localities if loc['id'] == locality_id), "Unknown")
        print(f"  Locality {locality_id} ({locality_name}): {count} neighborhoods")

    # Locality summary
    print(f"\nTotal localities: {len(localities)}")
    locality_ids = [loc['id'] for loc in localities]
    print(f"Locality ID range: {min(locality_ids)} to {max(locality_ids)}")
    print(f"Any gaps in locality IDs: {sorted(set(range(min(locality_ids), max(locality_ids) + 1)) - set(locality_ids))}")

def make_observations():
    """Make observations based on the analysis."""
    print("\n===== OBSERVATIONS =====")
    print("1. The import script attempts to create a 'Desconocido' neighborhood with ID 688")
    print("2. This neighborhood would be linked to a 'Desconocida' locality with ID 14")
    print("3. However, locality ID 14 doesn't exist in the localities.json file")
    print("4. 5,707 biodiversity records reference neighborhood ID 688")
    print("5. This suggests an evolution in your data model:")
    print("   - Previously: Bio records linked directly to localities")
    print("   - Now: Bio records linked to neighborhoods, which link to localities")
    print("6. The KeyError during import occurs because the script tries to reference")
    print("   the neighborhood with ID 688 which doesn't exist in your hoods.json")

def suggest_solutions():
    """Suggest possible solutions."""
    print("\n===== POSSIBLE SOLUTIONS =====")
    print("Option 1: Add the missing data")
    print("  - Add locality with ID 14 named 'Desconocida' to localities.json")
    print("  - Add neighborhood with ID 688 named 'Desconocido' to hoods.json")
    print("  - Link this neighborhood to locality ID 14")
    print("\nOption 2: Modify the import script")
    print("  - Update the _create_unknown_locality method to create locality ID 14")
    print("    even if it doesn't exist in the data")
    print("  - Ensure _create_unknown_neighborhood can handle this case")
    print("\nOption 3: Update the data model")
    print("  - Make the neighborhood field optional in BiodiversityRecord")
    print("  - Fall back to using locality for records without a valid neighborhood")

if __name__ == "__main__":
    try:
        # Load data
        bio_df, hoods, localities = load_data()
        
        # Run analyses
        analyze_hoods_ids(bio_df, hoods)
        check_hierarchical_relationships(hoods, localities)
        analyze_site_localities(bio_df, hoods)
        analyze_sites_data(bio_df)
        
        # Generate summary report
        generate_summary_report(bio_df, hoods, localities)
        
        # Make observations and suggest solutions
        make_observations()
        suggest_solutions()
        
    except Exception as e:
        print(f"Error: {e}")